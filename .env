# ==========================================
# LLM 大模型配置
# ==========================================

# 使用Bella配置 【bella 能选用的模型需要去官网查看】
LLM_PROVIDER=bella
LLM_API_KEY=922b7acb-c129-461f-96b8-603560315e4a
LLM_API_URL=https://api.bella.top/v1/chat/completions
LLM_MODEL=qwen2.5-7b-instruct

# 使用Google Gemini配置
# LLM_PROVIDER=gemini
# LLM_API_KEY=AIzaSyA0XP9Y6BLmWTl0ZlD7hNkCaST-3wiq-7o
# LLM_API_URL=https://generativelanguage.googleapis.com/v1beta
# LLM_MODEL=gemini-2.5-flash

# 其他配置选项（注释掉）:

# 方案1: 使用Mock模式（推荐用于测试）
# LLM_PROVIDER=mock

# 方案2: 使用OpenAI（需要真实API密钥）
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-your-openai-api-key-here
# LLM_API_URL=https://api.openai.com/v1/chat/completions
# LLM_MODEL=gpt-3.5-turbo

# 方案3: 使用Bella Provider（需要真实API密钥）
# LLM_PROVIDER=bella
# LLM_API_KEY=your-bella-api-key-here
# LLM_API_URL=https://api.bella.com/v1/chat/completions
# LLM_MODEL=gpt-4o

# ==========================================
# 数据库配置
# ==========================================
DB_PATH=./qa_database.db

# ==========================================
# 服务器配置
# ==========================================
PORT=8080

# ==========================================
# 其他配置
# ==========================================
LOG_LEVEL=info